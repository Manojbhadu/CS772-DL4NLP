{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "I12c8m4J7VtG"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import re\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, InputLayer, Activation, Flatten, Embedding, LSTM,GRU, Bidirectional, SimpleRNN\n",
    "from keras.initializers import Constant\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
    "import seaborn as sns\n",
    "import gensim\n",
    "import gensim.downloader\n",
    "from nltk.corpus import brown\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "or_xnXj47bSk",
    "outputId": "87466f26-a224-4d29-c1ef-5c59e9537d1e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /home/piyush/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/piyush/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('brown')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "RA88Qin47mim"
   },
   "outputs": [],
   "source": [
    "sents = brown.sents()\n",
    "cleaned_sents = []\n",
    "for i in sents:\n",
    "    sentence = []\n",
    "    for j in i :\n",
    "        if j not in string.punctuation :\n",
    "            sentence.append(j.lower())\n",
    "    cleaned_sents.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "dNKsgAZw7pBv"
   },
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(cleaned_sents,size=50,window=7,min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "jii8drzu7t0C"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"./train.csv\")\n",
    "test = pd.read_csv(\"./test.csv\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        This book was very informative, covering all a...\n",
       "1        I am already a baseball fan and knew a bit abo...\n",
       "2        I didn't like this product it smudged all unde...\n",
       "3        I simply love the product. I appreciate print ...\n",
       "4        It goes on very easily and makes my eyes look ...\n",
       "                               ...                        \n",
       "49995                         it does not work((((((((((((\n",
       "49996    Really worthless, loud motor with absolutely n...\n",
       "49997    Don't waste your money on this. It does nothin...\n",
       "49998    Product does not remove ear wax. No suction, j...\n",
       "49999    If you wear hearing aids these are great for r...\n",
       "Name: reviews, Length: 50000, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['reviews']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_counts(ratings):    \n",
    "    # find # of elements of each class\n",
    "    cnts = ratings.value_counts()\n",
    "    class1_count = cnts[1]\n",
    "    class2_count = cnts[2]\n",
    "    class3_count = cnts[3]\n",
    "    class4_count = cnts[4]\n",
    "    class5_count = cnts[5]\n",
    "    \n",
    "    return class1_count, class2_count, class3_count, class4_count, class5_count\n",
    "\n",
    "def majority_class_count(ratings):\n",
    "    return max(class_counts(ratings))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class1_data = train[train['ratings']==1]\n",
    "class2_data = train[train['ratings']==2]\n",
    "class3_data = train[train['ratings']==3]\n",
    "class4_data = train[train['ratings']==4]\n",
    "class5_data = train[train['ratings']==5]\n",
    "\n",
    "majority_class_cnt = majority_class_count(train['ratings'])\n",
    "class1_data = class1_data.sample(majority_class_cnt, random_state=1,replace=True)\n",
    "class2_data = class2_data.sample(majority_class_cnt, random_state=1,replace=True)\n",
    "class3_data = class3_data.sample(majority_class_cnt, random_state=1,replace=True)\n",
    "class4_data = class4_data.sample(majority_class_cnt, random_state=1,replace=True)\n",
    "class5_data = class5_data.sample(majority_class_cnt, random_state=1,replace=True)\n",
    "\n",
    "train = pd.concat([class1_data, class2_data, class3_data, class4_data, class5_data], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16477    Brush overheats.  I have bought several and th...\n",
       "4339     The bottle developed a huge crack within a cou...\n",
       "49474    4 of the same rings and they don't fit my fing...\n",
       "16781    I wa really hoping this smelled like almond. H...\n",
       "48624    I wore them attached to my lanyard. After less...\n",
       "                               ...                        \n",
       "29858    Better than triple antibiotic creams. I have a...\n",
       "43880    We have got one of these for each station - ou...\n",
       "27885    Really Beautiful color looks great and color i...\n",
       "2832     Go ahead and buy this, it is perfectly suited ...\n",
       "6673     Lotion is smooth and rich. The Bath Gel and Sh...\n",
       "Name: reviews, Length: 165965, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['reviews']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "3LEkE2gW79M3"
   },
   "outputs": [],
   "source": [
    "def convert_to_lower(text):\n",
    "    # return the reviews after convering then to lowercase\n",
    "    lower_text = text.copy()\n",
    "    for i in range(len(text)):\n",
    "        lower_text[i] = text[i].lower()\n",
    "    return lower_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "vCoZIT5D8LNW"
   },
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    #stop_words = set(stopwords.words('english'))\n",
    "    without_punctuation_text  = text.copy()\n",
    "    for i in range(len(text)):\n",
    "        without_punctuation_text[i] = [w for w in text[i] if w.isalpha()]\n",
    "    return without_punctuation_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "79MyWmLA8L5e"
   },
   "outputs": [],
   "source": [
    "def perform_tokenization(text):\n",
    "    tokenize_text = text.copy()\n",
    "    for i in range(len(text)):\n",
    "        tokenize_text[i] = nltk.word_tokenize(text[i])\n",
    "    return tokenize_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "cjRYpCYE8OIB"
   },
   "outputs": [],
   "source": [
    "def get_dicts(train):\n",
    "    reviews = train[\"reviews\"].to_list()\n",
    "    reviews = convert_to_lower(reviews)\n",
    "    reviews = perform_tokenization(reviews)\n",
    "    reviews = remove_punctuation(reviews)\n",
    "    return reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "_pZ_Ql8j8okK"
   },
   "outputs": [],
   "source": [
    "review = get_dicts(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jNohIEB68uaV"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "C6bGccvzC5jj"
   },
   "outputs": [],
   "source": [
    "max_length=50\n",
    "Embedding_dimension=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "yUZXOSWx9JlM"
   },
   "outputs": [],
   "source": [
    "tokenizer_obj = Tokenizer()\n",
    "tokenizer_obj.fit_on_texts(review) \n",
    "sequences = tokenizer_obj.texts_to_sequences(review)\n",
    "word_index = tokenizer_obj.word_index\n",
    "review_pad = pad_sequences(sequences, maxlen=max_length) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "KnRhFg329POP"
   },
   "outputs": [],
   "source": [
    "num_words = len(word_index)+1\n",
    "embedding_matrix = np.zeros ((num_words, Embedding_dimension))\n",
    "for word, i in word_index.items():\n",
    "  try:\n",
    "    embedding_vector = model.wv[word]\n",
    "    embedding_matrix[i] = embedding_vector\n",
    "  except:\n",
    "    continue "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rating_list = train['ratings'].to_list()\n",
    "Y = [str(i-1) for i in train_rating_list]\n",
    "y_train = tf.keras.utils.to_categorical(Y,num_classes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_test(test_reviews):\n",
    "  reviews = test_reviews\n",
    "  reviews = convert_to_lower(reviews)\n",
    "  reviews = perform_tokenization(reviews)\n",
    "  reviews = remove_punctuation(reviews)\n",
    "  return reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_review = preprocess_test(test['reviews'])\n",
    "test_review = test_review.to_list()\n",
    "sequences_test = tokenizer_obj.texts_to_sequences(test_review)\n",
    "test_review_pad = pad_sequences(sequences_test, maxlen=max_length) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = test['ratings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, test_reviews):\n",
    "        y_pred = model.predict(test_reviews)\n",
    "        pred1 = []\n",
    "        for i in range(len(y_pred)):\n",
    "            pred1.append(np.argmax(y_pred[i])+1)\n",
    "        return pred1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(y_pred,y_test,Model,modelName):\n",
    "    print(\"For model = \",modelName)\n",
    "    Classification_report = classification_report(y_test,y_pred,target_names=['1','2','3','4','5'])\n",
    "    cm  = confusion_matrix(test['ratings'],y_pred)\n",
    "    print(\"Classification Report : \\n\",Classification_report)\n",
    "    print(\"Heat Map :\\n\")\n",
    "    sns.heatmap(cm,cmap=\"Blues\",annot=True,fmt='.4g',xticklabels=['1','2','3','4','5'],yticklabels=['1','2','3','4','5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "Vr1_dmnoF9Pl"
   },
   "outputs": [],
   "source": [
    "def lstmModel():\n",
    "    model = Sequential()\n",
    "    embedding_layer = Embedding(num_words,Embedding_dimension,embeddings_initializer=Constant(embedding_matrix), input_length = max_length, trainable=False)\n",
    "    model.add(embedding_layer)\n",
    "    model.add(LSTM(units=64, dropout=0.2,recurrent_dropout=0.2))\n",
    "    model.add (Dense (64, activation='sigmoid'))\n",
    "    model.add (Dense (5, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wyoLWrJnGMzS",
    "outputId": "909f4669-fa96-4474-e489-ebc312bc3fdf",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1945/1945 [==============================] - 95s 49ms/step - loss: 1.2290 - accuracy: 0.4219 - val_loss: 7.4903 - val_accuracy: 0.1263\n",
      "Epoch 2/15\n",
      "1945/1945 [==============================] - 95s 49ms/step - loss: 1.1090 - accuracy: 0.5036 - val_loss: 8.7427 - val_accuracy: 0.0999\n",
      "Epoch 3/15\n",
      "1945/1945 [==============================] - 94s 48ms/step - loss: 1.0264 - accuracy: 0.5551 - val_loss: 9.6250 - val_accuracy: 0.1211\n",
      "Epoch 4/15\n",
      "1945/1945 [==============================] - 95s 49ms/step - loss: 0.9618 - accuracy: 0.5932 - val_loss: 10.5290 - val_accuracy: 0.1125\n",
      "Epoch 5/15\n",
      "1945/1945 [==============================] - 95s 49ms/step - loss: 0.9111 - accuracy: 0.6185 - val_loss: 11.2512 - val_accuracy: 0.1175\n",
      "Epoch 6/15\n",
      "1945/1945 [==============================] - 95s 49ms/step - loss: 0.8770 - accuracy: 0.6380 - val_loss: 12.1640 - val_accuracy: 0.1153\n",
      "Epoch 7/15\n",
      "1945/1945 [==============================] - 95s 49ms/step - loss: 0.8462 - accuracy: 0.6538 - val_loss: 12.8956 - val_accuracy: 0.1310\n",
      "Epoch 8/15\n",
      "1945/1945 [==============================] - 95s 49ms/step - loss: 0.8246 - accuracy: 0.6651 - val_loss: 13.5676 - val_accuracy: 0.1114\n",
      "Epoch 9/15\n",
      "1945/1945 [==============================] - 95s 49ms/step - loss: 0.8061 - accuracy: 0.6730 - val_loss: 14.4999 - val_accuracy: 0.1365\n",
      "Epoch 10/15\n",
      "1945/1945 [==============================] - 95s 49ms/step - loss: 0.7893 - accuracy: 0.6795 - val_loss: 15.2377 - val_accuracy: 0.1236\n",
      "Epoch 11/15\n",
      "1945/1945 [==============================] - 95s 49ms/step - loss: 0.7797 - accuracy: 0.6849 - val_loss: 15.9000 - val_accuracy: 0.1166\n",
      "Epoch 12/15\n",
      "1071/1945 [===============>..............] - ETA: 40s - loss: 0.7709 - accuracy: 0.6889"
     ]
    }
   ],
   "source": [
    "lstm  = lstmModel()\n",
    "lstm.fit(review_pad, y_train, batch_size=64, epochs=15, validation_split=0.25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7V6q9e3MJB8q"
   },
   "outputs": [],
   "source": [
    "y_pred = predict(lstm, test_review_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EsUmxfLdLfk2"
   },
   "outputs": [],
   "source": [
    "report(y_pred, y_test, lstm,\"LSTM Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n5D6WxvcLtAr",
    "outputId": "3ae3b44b-30de-453d-92cd-21820f71a9f4"
   },
   "outputs": [],
   "source": [
    "def bilstmModel():\n",
    "    model = Sequential()\n",
    "    embedding_layer = Embedding(num_words,Embedding_dimension,embeddings_initializer=Constant(embedding_matrix), input_length = max_length, trainable=False)\n",
    "    model.add(embedding_layer)\n",
    "    model.add(Bidirectional(LSTM(units=64, dropout=0.2,recurrent_dropout=0.2)))\n",
    "    model.add (Dense (64, activation='sigmoid'))\n",
    "    model.add (Dense (5, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UcHyo1gBMKXB"
   },
   "outputs": [],
   "source": [
    "bilstm  = bilstmModel()\n",
    "bilstm.fit(review_pad, y_train, batch_size=64, epochs=15, validation_split=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WZk3DHLSO6yB"
   },
   "outputs": [],
   "source": [
    "y_pred = predict(bilstm, test_review_pad)\n",
    "report(y_pred, y_test, bilstm,\"Bi-LSTM Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "egDw41FpOgp0"
   },
   "outputs": [],
   "source": [
    "def gruModel():\n",
    "    model = Sequential()\n",
    "    embedding_layer = Embedding(num_words,Embedding_dimension,embeddings_initializer=Constant(embedding_matrix), input_length = max_length, trainable=False)\n",
    "    model.add(embedding_layer)\n",
    "    model.add(GRU(units= 64,dropout=0.2,recurrent_dropout=0.2))\n",
    "    model.add (Dense (64, activation='sigmoid'))\n",
    "    model.add (Dense (5, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "opPWqbT2O5-Y"
   },
   "outputs": [],
   "source": [
    "gru  = gruModel()\n",
    "gru.fit(review_pad, y_train, batch_size=64, epochs=15, validation_split=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hZDhiUxkO0xD"
   },
   "outputs": [],
   "source": [
    "y_pred = predict(gru, test_review_pad)\n",
    "report(y_pred, y_test, gru,\"GRU Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6z5HEsBjPbHF"
   },
   "outputs": [],
   "source": [
    "def bigruModel():\n",
    "    model = Sequential()\n",
    "    embedding_layer = Embedding(num_words,Embedding_dimension,embeddings_initializer=Constant(embedding_matrix), input_length = max_length, trainable=False)\n",
    "    model.add(embedding_layer)\n",
    "    model.add(Bidirectional(GRU(units= 64,dropout=0.2,recurrent_dropout=0.2)))\n",
    "    model.add (Dense (64, activation='sigmoid'))\n",
    "    model.add (Dense (5, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 520
    },
    "id": "Qb73ktrKPdWB",
    "outputId": "e164d3d1-dd51-4998-a805-4b9681bf4179"
   },
   "outputs": [],
   "source": [
    "bigru  = bigruModel()\n",
    "bigru.fit(review_pad, y_train, batch_size=64, epochs=15, validation_split=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xCdfsVcCPsgR"
   },
   "outputs": [],
   "source": [
    "y_pred = predict(bigru, test_review_pad)\n",
    "report(y_pred, y_test, bigru,\"Bidirectional GRU Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnnModel():\n",
    "    model = Sequential()\n",
    "    embedding_layer = Embedding(num_words,Embedding_dimension,embeddings_initializer=Constant(embedding_matrix), input_length = max_length, trainable=False)\n",
    "    model.add(embedding_layer)\n",
    "    model.add(SimpleRNN(units= 64,dropout=0.2,recurrent_dropout=0.2))\n",
    "    model.add (Dense (64, activation='sigmoid'))\n",
    "    model.add (Dense (5, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn  = rnnModel()\n",
    "rnn.fit(review_pad, y_train, batch_size=64, epochs=15, validation_split=0.25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = predict(rnn, test_review_pad)\n",
    "report(y_pred, y_test, rnn,\"RNN Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Pretrained_lstm.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
