{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "I12c8m4J7VtG"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import re\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, InputLayer, Activation, Flatten, Embedding, LSTM,GRU, Bidirectional, SimpleRNN\n",
    "from keras.initializers import Constant\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
    "import seaborn as sns\n",
    "import gensim\n",
    "import gensim.downloader\n",
    "from nltk.corpus import brown\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "or_xnXj47bSk",
    "outputId": "87466f26-a224-4d29-c1ef-5c59e9537d1e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /home/piyush/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/piyush/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('brown')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "RA88Qin47mim"
   },
   "outputs": [],
   "source": [
    "sents = brown.sents()\n",
    "cleaned_sents = []\n",
    "for i in sents:\n",
    "    sentence = []\n",
    "    for j in i :\n",
    "        if j not in string.punctuation :\n",
    "            sentence.append(j.lower())\n",
    "    cleaned_sents.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "dNKsgAZw7pBv"
   },
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(cleaned_sents,size=50,window=7,min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "jii8drzu7t0C"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"./train.csv\")\n",
    "test = pd.read_csv(\"./test.csv\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        This book was very informative, covering all a...\n",
       "1        I am already a baseball fan and knew a bit abo...\n",
       "2        I didn't like this product it smudged all unde...\n",
       "3        I simply love the product. I appreciate print ...\n",
       "4        It goes on very easily and makes my eyes look ...\n",
       "                               ...                        \n",
       "49995                         it does not work((((((((((((\n",
       "49996    Really worthless, loud motor with absolutely n...\n",
       "49997    Don't waste your money on this. It does nothin...\n",
       "49998    Product does not remove ear wax. No suction, j...\n",
       "49999    If you wear hearing aids these are great for r...\n",
       "Name: reviews, Length: 50000, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['reviews']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_counts(ratings):    \n",
    "    # find # of elements of each class\n",
    "    cnts = ratings.value_counts()\n",
    "    class1_count = cnts[1]\n",
    "    class2_count = cnts[2]\n",
    "    class3_count = cnts[3]\n",
    "    class4_count = cnts[4]\n",
    "    class5_count = cnts[5]\n",
    "    \n",
    "    return class1_count, class2_count, class3_count, class4_count, class5_count\n",
    "\n",
    "def majority_class_count(ratings):\n",
    "    return max(class_counts(ratings))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class1_data = train[train['ratings']==1]\n",
    "class2_data = train[train['ratings']==2]\n",
    "class3_data = train[train['ratings']==3]\n",
    "class4_data = train[train['ratings']==4]\n",
    "class5_data = train[train['ratings']==5]\n",
    "\n",
    "majority_class_cnt = majority_class_count(train['ratings'])\n",
    "class1_data = class1_data.sample(majority_class_cnt, random_state=1,replace=True)\n",
    "class2_data = class2_data.sample(majority_class_cnt, random_state=1,replace=True)\n",
    "class3_data = class3_data.sample(majority_class_cnt, random_state=1,replace=True)\n",
    "class4_data = class4_data.sample(majority_class_cnt, random_state=1,replace=True)\n",
    "class5_data = class5_data.sample(majority_class_cnt, random_state=1,replace=True)\n",
    "\n",
    "train = pd.concat([class1_data, class2_data, class3_data, class4_data, class5_data], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16477    Brush overheats.  I have bought several and th...\n",
       "4339     The bottle developed a huge crack within a cou...\n",
       "49474    4 of the same rings and they don't fit my fing...\n",
       "16781    I wa really hoping this smelled like almond. H...\n",
       "48624    I wore them attached to my lanyard. After less...\n",
       "                               ...                        \n",
       "29858    Better than triple antibiotic creams. I have a...\n",
       "43880    We have got one of these for each station - ou...\n",
       "27885    Really Beautiful color looks great and color i...\n",
       "2832     Go ahead and buy this, it is perfectly suited ...\n",
       "6673     Lotion is smooth and rich. The Bath Gel and Sh...\n",
       "Name: reviews, Length: 165965, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['reviews']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "3LEkE2gW79M3"
   },
   "outputs": [],
   "source": [
    "def convert_to_lower(text):\n",
    "    # return the reviews after convering then to lowercase\n",
    "    lower_text = text.copy()\n",
    "    for i in range(len(text)):\n",
    "        lower_text[i] = text[i].lower()\n",
    "    return lower_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "vCoZIT5D8LNW"
   },
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    #stop_words = set(stopwords.words('english'))\n",
    "    without_punctuation_text  = text.copy()\n",
    "    for i in range(len(text)):\n",
    "        without_punctuation_text[i] = [w for w in text[i] if w.isalpha()]\n",
    "    return without_punctuation_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "79MyWmLA8L5e"
   },
   "outputs": [],
   "source": [
    "def perform_tokenization(text):\n",
    "    tokenize_text = text.copy()\n",
    "    for i in range(len(text)):\n",
    "        tokenize_text[i] = nltk.word_tokenize(text[i])\n",
    "    return tokenize_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "cjRYpCYE8OIB"
   },
   "outputs": [],
   "source": [
    "def get_dicts(train):\n",
    "    reviews = train[\"reviews\"].to_list()\n",
    "    reviews = convert_to_lower(reviews)\n",
    "    reviews = perform_tokenization(reviews)\n",
    "    reviews = remove_punctuation(reviews)\n",
    "    return reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "_pZ_Ql8j8okK"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-82113b90c459>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mreview\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_dicts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-a9704a4c7c92>\u001b[0m in \u001b[0;36mget_dicts\u001b[0;34m(train)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_dicts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mreviews\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"reviews\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mreviews\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_lower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreviews\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mreviews\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mperform_tokenization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreviews\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mreviews\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremove_punctuation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreviews\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-5e6103d7a994>\u001b[0m in \u001b[0;36mconvert_to_lower\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mlower_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mlower_text\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlower_text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5178\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5179\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5180\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5182\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "review = get_dicts(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jNohIEB68uaV"
   },
   "outputs": [],
   "source": [
    "review = review.to_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C6bGccvzC5jj"
   },
   "outputs": [],
   "source": [
    "max_length=50\n",
    "Embedding_dimension=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yUZXOSWx9JlM"
   },
   "outputs": [],
   "source": [
    "tokenizer_obj = Tokenizer()\n",
    "tokenizer_obj.fit_on_texts(review) \n",
    "sequences = tokenizer_obj.texts_to_sequences(review)\n",
    "word_index = tokenizer_obj.word_index\n",
    "review_pad = pad_sequences(sequences, maxlen=max_length) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KnRhFg329POP"
   },
   "outputs": [],
   "source": [
    "num_words = len(word_index)+1\n",
    "embedding_matrix = np.zeros ((num_words, Embedding_dimension))\n",
    "for word, i in word_index.items():\n",
    "  try:\n",
    "    embedding_vector = model.wv[word]\n",
    "    embedding_matrix[i] = embedding_vector\n",
    "  except:\n",
    "    continue "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rating_list = train['ratings'].to_list()\n",
    "Y = [str(i-1) for i in train_rating_list]\n",
    "y_train = tf.keras.utils.to_categorical(Y,num_classes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_test(test_reviews):\n",
    "  reviews = test_reviews\n",
    "  reviews = convert_to_lower(reviews)\n",
    "  reviews = perform_tokenization(reviews)\n",
    "  reviews = remove_punctuation(reviews)\n",
    "  return reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_review = preprocess_test(test['reviews'])\n",
    "test_review = test_review.to_list()\n",
    "sequences_test = tokenizer_obj.texts_to_sequences(test_review)\n",
    "test_review_pad = pad_sequences(sequences_test, maxlen=max_length) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = test['ratings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, test_reviews):\n",
    "        y_pred = model.predict(test_reviews)\n",
    "        pred1 = []\n",
    "        for i in range(len(y_pred)):\n",
    "            pred1.append(np.argmax(y_pred[i])+1)\n",
    "        return pred1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(y_pred,y_test,Model,modelName):\n",
    "    print(\"For model = \",modelName)\n",
    "    Classification_report = classification_report(y_test,y_pred,target_names=['1','2','3','4','5'])\n",
    "    cm  = confusion_matrix(test['ratings'],y_pred)\n",
    "    print(\"Classification Report : \\n\",Classification_report)\n",
    "    print(\"Heat Map :\\n\")\n",
    "    sns.heatmap(cm,cmap=\"Blues\",annot=True,fmt='.4g',xticklabels=['1','2','3','4','5'],yticklabels=['1','2','3','4','5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vr1_dmnoF9Pl"
   },
   "outputs": [],
   "source": [
    "def lstmModel():\n",
    "    model = Sequential()\n",
    "    embedding_layer = Embedding(num_words,Embedding_dimension,embeddings_initializer=Constant(embedding_matrix), input_length = max_length, trainable=False)\n",
    "    model.add(embedding_layer)\n",
    "    model.add(LSTM(units=64, dropout=0.2,recurrent_dropout=0.2))\n",
    "    model.add (Dense (64, activation='sigmoid'))\n",
    "    model.add (Dense (5, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wyoLWrJnGMzS",
    "outputId": "909f4669-fa96-4474-e489-ebc312bc3fdf",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lstm  = lstmModel()\n",
    "lstm.fit(review_pad, y_train, batch_size=64, epochs=15, validation_split=0.25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7V6q9e3MJB8q"
   },
   "outputs": [],
   "source": [
    "y_pred = predict(lstm, test_review_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EsUmxfLdLfk2"
   },
   "outputs": [],
   "source": [
    "report(y_pred, y_test, lstm,\"LSTM Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n5D6WxvcLtAr",
    "outputId": "3ae3b44b-30de-453d-92cd-21820f71a9f4"
   },
   "outputs": [],
   "source": [
    "def bilstmModel():\n",
    "    model = Sequential()\n",
    "    embedding_layer = Embedding(num_words,Embedding_dimension,embeddings_initializer=Constant(embedding_matrix), input_length = max_length, trainable=False)\n",
    "    model.add(embedding_layer)\n",
    "    model.add(Bidirectional(LSTM(units=64, dropout=0.2,recurrent_dropout=0.2)))\n",
    "    model.add (Dense (64, activation='sigmoid'))\n",
    "    model.add (Dense (5, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UcHyo1gBMKXB"
   },
   "outputs": [],
   "source": [
    "bilstm  = bilstmModel()\n",
    "bilstm.fit(review_pad, y_train, batch_size=64, epochs=15, validation_split=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WZk3DHLSO6yB"
   },
   "outputs": [],
   "source": [
    "y_pred = predict(bilstm, test_review_pad)\n",
    "report(y_pred, y_test, bilstm,\"Bi-LSTM Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "egDw41FpOgp0"
   },
   "outputs": [],
   "source": [
    "def gruModel():\n",
    "    model = Sequential()\n",
    "    embedding_layer = Embedding(num_words,Embedding_dimension,embeddings_initializer=Constant(embedding_matrix), input_length = max_length, trainable=False)\n",
    "    model.add(embedding_layer)\n",
    "    model.add(GRU(units= 64,dropout=0.2,recurrent_dropout=0.2))\n",
    "    model.add (Dense (64, activation='sigmoid'))\n",
    "    model.add (Dense (5, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "opPWqbT2O5-Y"
   },
   "outputs": [],
   "source": [
    "gru  = gruModel()\n",
    "gru.fit(review_pad, y_train, batch_size=64, epochs=15, validation_split=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hZDhiUxkO0xD"
   },
   "outputs": [],
   "source": [
    "y_pred = predict(gru, test_review_pad)\n",
    "report(y_pred, y_test, gru,\"GRU Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6z5HEsBjPbHF"
   },
   "outputs": [],
   "source": [
    "def bigruModel():\n",
    "    model = Sequential()\n",
    "    embedding_layer = Embedding(num_words,Embedding_dimension,embeddings_initializer=Constant(embedding_matrix), input_length = max_length, trainable=False)\n",
    "    model.add(embedding_layer)\n",
    "    model.add(Bidirectional(GRU(units= 64,dropout=0.2,recurrent_dropout=0.2)))\n",
    "    model.add (Dense (64, activation='sigmoid'))\n",
    "    model.add (Dense (5, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 520
    },
    "id": "Qb73ktrKPdWB",
    "outputId": "e164d3d1-dd51-4998-a805-4b9681bf4179"
   },
   "outputs": [],
   "source": [
    "bigru  = bigruModel()\n",
    "bigru.fit(review_pad, y_train, batch_size=64, epochs=15, validation_split=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xCdfsVcCPsgR"
   },
   "outputs": [],
   "source": [
    "y_pred = predict(bigru, test_review_pad)\n",
    "report(y_pred, y_test, bigru,\"Bidirectional GRU Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnnModel():\n",
    "    model = Sequential()\n",
    "    embedding_layer = Embedding(num_words,Embedding_dimension,embeddings_initializer=Constant(embedding_matrix), input_length = max_length, trainable=False)\n",
    "    model.add(embedding_layer)\n",
    "    model.add(SimpleRNN(units= 64,dropout=0.2,recurrent_dropout=0.2))\n",
    "    model.add (Dense (64, activation='sigmoid'))\n",
    "    model.add (Dense (5, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn  = rnnModel()\n",
    "rnn.fit(review_pad, y_train, batch_size=64, epochs=15, validation_split=0.25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = predict(rnn, test_review_pad)\n",
    "report(y_pred, y_test, rnn,\"RNN Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Pretrained_lstm.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
